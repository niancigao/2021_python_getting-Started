{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats \n",
    "\n",
    "##### Progress bar (進度條)\n",
    "from tqdm import tqdm\n",
    "\n",
    "##### KFOLD\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "##### preprocessing  (預處理)\n",
    "from sklearn.preprocessing import QuantileTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d4724",
   "metadata": {},
   "source": [
    "# Quantile transformation\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "quantiletransformer will force features transform to same shape\n",
    "\n",
    "from tqdm import tqdm to visualize progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e07eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [col for col in test_df.columns]\n",
    "\n",
    "for col in tqdm(features):\n",
    "    transformer = QuantileTransformer(n_quantiles=5000, \n",
    "                                      random_state=42, \n",
    "                                      output_distribution=\"normal\")\n",
    "    \n",
    "    vec_len = len(train_df[col].values)\n",
    "    vec_len_test = len(test_df[col].values)\n",
    "\n",
    "    raw_vec = train_df[col].values.reshape(vec_len, 1)\n",
    "    test_vec = test_df[col].values.reshape(vec_len_test, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "    \n",
    "    train_df[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_df[col] = transformer.transform(test_vec).reshape(1, vec_len_test)[0]\n",
    "\n",
    "print(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441204d1",
   "metadata": {},
   "source": [
    "# KFOLD\n",
    "\n",
    "import KFold from sklearn.model_selection\n",
    "you can also import train_test_split from skleran.model_selection\n",
    "\n",
    "If your data is sensitive to cardinality of categorical, \n",
    "import StratifiedKFold from sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Set your configuration here!!\n",
    "\n",
    "FOLD = 5\n",
    "SEEDS = [24, 42]\n",
    "\n",
    "fet_imp = 0 # feature importance (not necessary)\n",
    "counter = 0\n",
    "oof_score = 0\n",
    "\n",
    "##### here I use XGBoost to implement KFold, you may choose your model by your self\n",
    "y_pred_final_xgb = np.zeros((Xtest.shape[0], 1))\n",
    "y_pred_meta_xgb = np.zeros((Xtrain.shape[0], 1))\n",
    "\n",
    "##### your chosen seeds\n",
    "for sidx, seed in enumerate(SEEDS):\n",
    "    seed_score = 0\n",
    "    \n",
    "    ##### start KFold\n",
    "    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n",
    "\n",
    "    for idx, (train, val) in enumerate(kfold.split(Xtrain.values, Ytrain.values)):\n",
    "        counter += 1\n",
    "        \n",
    "        ##### setting sub training data and validation data\n",
    "        train_x, train_y = Xtrain.iloc[train], Ytrain.iloc[train]\n",
    "        val_x, val_y = Xtrain.iloc[val], Ytrain.iloc[val]\n",
    "        \n",
    "        \n",
    "        ##### This is nothing to do with KFold\n",
    "        params['learning_rate']=0.02\n",
    "        init_model = XGBClassifier(**params)\n",
    "        \n",
    "        ##### You may fit your model here!\n",
    "        init_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (val_x, val_y)], \n",
    "                       early_stopping_rounds=200, verbose=500)\n",
    "        \n",
    "        ##### Ignore this block\n",
    "        params['learning_rate']=0.01\n",
    "        model = XGBClassifier(**params)\n",
    "\n",
    "        model.fit(train_x, train_y, eval_set=[(train_x, train_y), (val_x, val_y)], \n",
    "                  early_stopping_rounds=100, verbose=300, xgb_model=init_model)\n",
    "        \n",
    "        ##### predict validation set and testing set\n",
    "        y_pred = model.predict_proba(val_x, iteration_range=(0, model.best_iteration))[:,-1]\n",
    "        y_pred_meta_xgb[val] += np.array([y_pred]).T\n",
    "        y_pred_final_xgb += np.array([model.predict_proba(Xtest, iteration_range=(0, model.best_iteration))[:,-1]]).T\n",
    "        \n",
    "        ##### calculate your metrics here\n",
    "        fet_imp += model.feature_importances_\n",
    "        score = roc_auc_score(val_y, y_pred)\n",
    "        oof_score += score\n",
    "        seed_score += score\n",
    "        \n",
    "        ##### metric logger\n",
    "        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n",
    "    \n",
    "    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n",
    "\n",
    "\n",
    "fet_imp = fet_imp / float(counter)\n",
    "y_pred_meta_xgb = y_pred_meta_xgb / float(len(SEEDS))\n",
    "y_pred_final_xgb = y_pred_final_xgb / float(counter)\n",
    "oof_score /= float(counter)\n",
    "print(\"Aggregate OOF Score: {}\".format(oof_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9a6f1e",
   "metadata": {},
   "source": [
    "# Plot confusion matrix\n",
    "\n",
    "confusion matrix is always a great visualization tool to justify your model performance.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e13ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### you may import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix', fontweight='bold', pad=15)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontweight='bold')\n",
    "    plt.xlabel('Predicted label', fontweight='bold')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4dc2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(Ytrain, y_pred, labels=[0, 1])\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc952c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa7e9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
